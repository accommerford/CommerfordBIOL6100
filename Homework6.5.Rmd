---
title: "Homework 6"
author: "Audrey Commerford"
date: "2025-02-22"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Creating Fake Data Sets To Explore Hypotheses

I recently read a [new review](https://jamanetwork.com/journals/jama/article-abstract/2827212) of the decrease in cervical cancer following introduction of the HPV vaccine. I am loosely basing my  model off of their findings. However, this model does not account for the difference before and after introduction, so it is really just a model of change over time without accounting for vaccination. 

I started by establishing my explanatory and response variables. 

```{r}
# establish explanatory variable: years before and after the introduction of the HPV vaccine
year <- 1992:2021

# establish response variable: number of cervical cancer deaths
deaths <- rnorm(30, mean=39, sd=15)
```

I first created a simple model of years vs cervical cancer deaths. 

```{r}
data_frame <- data.frame(year, deaths)
str(data_frame)
```

To analyze this data, I used a linear model. Since it is randomly generated and distributed, there is little to no association between year and mortality. 

```{r}
# fitting a linear model
model <- lm(deaths~year)
summary(model)

# visualize dataset 
plot(year, deaths)
```

To test the effect of different sample sizes, I adjusted the total number of deaths that occurred over the study period. When the overall number of deaths is greater, the correlation is much stronger.

```{r}
year <- 1992:2021

# testing a large sample size 
total_deaths_large <- seq(from = 400, to = 50, length.out = 30)

for(i in 1:30) {
  large_sample_size <- data.frame(year = year, deaths = total_deaths_large)
  plot(large_sample_size[,1], large_sample_size[,2], xlab = "year", ylab = "deaths")
}

# testing a small sample size
total_deaths_small <- seq(from = 100, to = 10, length.out = 30)

for(i in 1:30) {
  small_sample_size <- data.frame(year = year, deaths = total_deaths_small)
  plot(small_sample_size[,1], small_sample_size[,2], xlab = "year", ylab = "deaths", ylim = c(0, 400))
}
```

To test different effect sizes, I added noise using random normal values. When the standard deviation of the noise variable is low, the effect is very strong and the plot is still very linear. When the standard deviation of the noise variable is high, the variation is much stronger and the effect is less distinct. 

```{r}
year <- 1992:2021
total_deaths <- seq(from = 400, to = 50, length.out = 30)
noise_small <- rnorm(30, mean = 0, sd = 5)

# testing a strong effect size (minimal noise)
for(i in 1:30) {
  large_effect_size <- data.frame(year = year, deaths = total_deaths + noise_small)
  plot(large_effect_size[,1], large_effect_size[,2], xlab = "year", ylab = "deaths")
}

# testing a weak effect size (a lot of noise)
noise_large <- rnorm(30, mean = 0, sd= 50)
for(i in 1:30) {
  small_effect_size <- data.frame(year = year, deaths = total_deaths + noise_large)
  plot(small_effect_size[,1], small_effect_size[,2], xlab = "year", ylab = "deaths")
}

```

In the study, the actual standard deviation was about 15 and there were only 55 deaths in the first year.

```{r}
year <- 1992:2021
sample <- seq(from = 55, to = 12, length.out = 30)
noise <- rnorm(30, mean = 0, sd = 15)

results <- data.frame(year = year, deaths = rep(NA, 30))

for(i in 1:30) {
  results[,2] <-  sample + noise
  plot(results[,1], results[,2], xlab = "year", ylab = "deaths")
}

model <- lm(deaths~year, data=results)
summary(model)
```
